README file for Programming Assignment 2 (Java edition)
=======================================================

Your directory should now contain the following files:

 build.xml
 README
 cool.lex
 test.cl
 tests/*
 AbstractSymbol.java  -> [course dir]/src/PA2J/AbstractSymbol.java
 BoolConst.java       -> [course dir]/src/PA2J/BoolConst.java
 Flags.java           -> [course dir]/src/PA2J/Flags.java
 IdSymbol.java        -> [course dir]/src/PA2J/IdSymbol.java
 IdTable.java         -> [course dir]/src/PA2J/IdTable.java
 IntSymbol.java       -> [course dir]/src/PA2J/IntSymbol.java
 IntTable.java        -> [course dir]/src/PA2J/IntTable.java
 Lexer.java           -> [course dir]/src/PA2J/Lexer.java
 AbstractTable.java   -> [course dir]/src/PA2J/AbstractTable.java
 StringSymbol.java    -> [course dir]/src/PA2J/StringSymbol.java
 StringTable.java     -> [course dir]/src/PA2J/StringTable.java
 Utilities.java       -> [course dir]/src/PA2J/Utilities.java
 TokenConstants.java  -> [course dir]/src/PA2J/TokenConstants.java
 *.java		      other generated files

	The build.xml contains targets for compiling and running your
	program. DO NOT MODIFY.

	The README contains this info. Part of the assignment is to fill
	the README with the write-up for your project. You should
	explain design decisions, explain why your code is correct, and
	why your test cases are adequate. It is part of the assignment
	to clearly and concisely explain things in text as well as to
	comment your code. Just edit this file.

	cool.lex is a skeleton file for the specification of the
	lexical analyzer. You should complete it with your regular
	expressions, patterns and actions. Information on how to do this
	is in the jlex manual, which is part of your reader.

	test.cl is a COOL program that you can test the lexical
	analyzer on. It contains some errors, so it won't compile with
	coolc. However, test.cl does not exercise all lexical
	constructs of COOL and part of your assignment is to rewrite
	test.cl with a complete set of tests for your lexical analyzer.

        tests is a directory containing five test cases with expected outputs.
        DO NOT MODIFY.

	TokenConstants.java contains constant definitions that are used by
	almost all parts of the compiler. DO NOT MODIFY.

	*Table.java and *Symbol.java contain string table data
	structures.  DO NOT MODIFY.

	Utilities.java contains various support functions used by the
	main lexer driver (Lexer.java).  DO NOT MODIFY.

	Lexer.java contains the main method which will call your lexer
	and print out the tokens that it returns.  DO NOT MODIFY.

        CoolLexer.java is the scanner generated by jlex from cool.lex.
        DO NOT MODIFY IT, as your changes will be overritten the next
        time you run jlex.

	mycoolc is a shell script that glues together the phases of the
	compiler using Unix pipes instead of statically linking code.  
	While inefficient, this architecture makes it easy to mix and match
	the components you write with those of the course compiler.
	DO NOT MODIFY.	

Instructions
------------

	Remember to make sure `~cs164/bin' is in your `path' variable.

	To compile your lexer type:

	% ant lexer

	Run your lexer by putting your test input in a file 'foo.cl' and
	run the lextest program:

	% ./lexer foo.cl

	To run your lexer on the file test.cl type:

	% ant test

        To run five examples in tests directory type:

        % ant test-all

	If you think your lexical analyzer is correct and behaves like
	the one we wrote, you can actually try 'mycoolc' and see whether
	it runs and produces correct code for the examples and your
	first assignment. If your lexical analyzer behaves in an
	unexpected manner, you may get errors anywhere, i.e. during
	parsing, during semantic analysis, during code generation or
	only when you run the produced code on spim. So beware.

	To turnin your work type:

	% ant submit-clean

	And run the "submit" program following the instructions on the
	course web page.
	
	Running "submit" will collect the files cool.lex, test.cl,
	README, and test.output. Don't forget to edit the README file to
	include your write-up, and to write your own test cases in
	test.cl.

 	You may turn in the assignment as many times as you like.
	However, only the last version will be retained for
	grading.

	GOOD LUCK!

---8<------8<------8<------8<---cut here---8<------8<------8<------8<---

Write-up for PA2J
-----------------

                        CS164 PA1 Deisgn Doc


        ----GROUP----
        Jaeseo Lee <jaeseolee96@gmail.com> login: dn
        Mingjie Zhao <jackzhao.mj@gmail.com> login: cp

        
        ----GENERAL DESIGN GOAL----
        In normal case, the lexer will read the program stream, return 
        <token-name, attribute-value> to the parser, and report error
        message.

        JFlex can generate lexer according to the ReGex we wrote. So our
        job is to wrote correct ReGex which matches the pattern, and do
        state-transformation for to execute different methods.


        ----HANDLE COMMENTS----
        The initial state, YYINITIAL will do the following: when '\n' is
        met, we increase the line number. And it will match patterns.

        Line comment is easy to match and it only transforms between two 
        states: YYINITIAL and LINE_COMMENT. 

        For nested comments, the YYINITIAL state will tranforms to COMMENT
        state when "(*" matches. In COMMENT state, we set a counter, 
        openCommentCounter, to keep track of the depth of nested comment.
        When "(*" is met, we add the counter by one. When "*)" is met,
        we first check if it is zero. If it is, we transform the state to 
        YYINITIAL. If not, we keep reading the the imput stream.

        If unnested comment occurs, we return the ERROR token with error
        message.

        If '\n' matches, we add the line number.


        ----HANDLE STRING----
        In initial state, if '\"' matches, the lexer transfer to STRING state.
        In string state, we handle three special cases: a too long string,
        unmatched string and special characters (i.e. null) inside a stirng.
        
        Whenever it appends a character into string buffer, it checks string 
        buffer's length, and if it is over 1024, then we return an error token,
        and keep lexing. When already returns a token, we do not check for null
        character. On the other hand, if it saw a null character before it reaches
        length limit, then we do not check the string length. In both cases, it
        still checks if the string is properly terminated.

        ----EOF----
        If EOF is inside a string or comment, it returns proper ERROR message.

        When it hits EOF, it checks the state of lexer. If it is in COMMENT,
        or STRING state, it implies that EOF is inside a string or comment.


        ----TESTS----
        Our code pass works well on tests in ./tests/. And we run "mycoolc"
        to compile the stack machine in PA1, everything goes well.

        Beside of these, we wrote other test for coner cases in test.cl. And 
        when implementing the requied lexing funcion specified in the handout, 
        we tested out funcion all the time.

        In test.cl, our tests focused on XX cases:

        When special characters (i.e. null) and  appears inside a comment.

        When escaped characters and EOF appears inside a string. And a too
        long string case.

        When invalid characters appears.

        The lexer works well for these corner cases.
        

        We wish to use slip our of roundup (10/60) hour.
        We are late for 10 minutes. Gods have mercy.

